{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgizmrkv\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20241031_235419-9hakvol3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gizmrkv/tuple-autoencoder/runs/9hakvol3' target=\"_blank\">2024-10-31_23-54-18</a></strong> to <a href='https://wandb.ai/gizmrkv/tuple-autoencoder' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gizmrkv/tuple-autoencoder' target=\"_blank\">https://wandb.ai/gizmrkv/tuple-autoencoder</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gizmrkv/tuple-autoencoder/runs/9hakvol3' target=\"_blank\">https://wandb.ai/gizmrkv/tuple-autoencoder/runs/9hakvol3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type      | Params | Mode \n",
      "------------------------------------------------\n",
      "0 | embedding | Embedding | 100    | train\n",
      "1 | linear    | Linear    | 1.1 K  | train\n",
      "------------------------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "2         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 49/49 [00:00<00:00, 51.09it/s, v_num=vol3]      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video logs/2024-10-31_23-54-18/embedding_evolution.mp4.\n",
      "Moviepy - Writing video logs/2024-10-31_23-54-18/embedding_evolution.mp4\n",
      "\n",
      "Epoch 19: 100%|██████████| 49/49 [00:01<00:00, 36.72it/s, v_num=vol3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !                                                     \n",
      "Moviepy - video ready logs/2024-10-31_23-54-18/embedding_evolution.mp4\n",
      "Epoch 19: 100%|██████████| 49/49 [00:01<00:00, 25.11it/s, v_num=vol3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `fps` argument does not affect the frame rate of the video when providing a file path or raw bytes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 49/49 [00:01<00:00, 25.07it/s, v_num=vol3]\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import lightning as L\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from moviepy.editor import ImageSequenceClip\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import wandb\n",
    "\n",
    "\n",
    "class PlotEmbeddingsCallback(Callback):\n",
    "    def __init__(self, log_dir: Path):\n",
    "        super().__init__()\n",
    "        self.log_dir = log_dir\n",
    "        self.log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def on_train_epoch_end(self, trainer: L.Trainer, pl_module: L.LightningModule):\n",
    "        embeddings = pl_module.embedding.weight.detach().cpu().numpy()\n",
    "\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.scatter(embeddings[:, 0], embeddings[:, 1])\n",
    "\n",
    "        for i in range(len(embeddings)):\n",
    "            plt.annotate(str(i), (embeddings[i, 0], embeddings[i, 1]))\n",
    "\n",
    "        plt.title(f\"Embedding Space at Epoch {trainer.current_epoch}\")\n",
    "        plt.xlabel(\"Dimension 1\")\n",
    "        plt.ylabel(\"Dimension 2\")\n",
    "\n",
    "        zero_pad = len(str(trainer.max_epochs))\n",
    "        filename = str(\n",
    "            self.log_dir / f\"embeddings_epoch_{trainer.current_epoch:0{zero_pad}}.png\"\n",
    "        )\n",
    "\n",
    "        plt.savefig(filename)\n",
    "        plt.close()\n",
    "\n",
    "        if isinstance(trainer.logger, WandbLogger):\n",
    "            trainer.logger.log_image(key=\"embeddings\", images=[wandb.Image(filename)])\n",
    "\n",
    "    def on_train_end(self, trainer: L.Trainer, pl_module: L.LightningModule):\n",
    "        image_files = sorted(list(self.log_dir.glob(\"embeddings_epoch_*.png\")))\n",
    "\n",
    "        clip = ImageSequenceClip([str(img) for img in image_files], fps=5)\n",
    "\n",
    "        clip.write_videofile(\n",
    "            str(self.log_dir / \"embedding_evolution.mp4\"),\n",
    "            fps=5,\n",
    "            codec=\"libx264\",\n",
    "            audio=False,\n",
    "        )\n",
    "\n",
    "        # wandbにも動画をログ\n",
    "        if isinstance(trainer.logger, WandbLogger):\n",
    "            trainer.logger.experiment.log(\n",
    "                {\n",
    "                    \"embedding_evolution\": wandb.Video(\n",
    "                        str(self.log_dir / \"embedding_evolution.mp4\"),\n",
    "                        fps=5,\n",
    "                        format=\"mp4\",\n",
    "                    )\n",
    "                }\n",
    "            )\n",
    "\n",
    "\n",
    "class TupleDataModule(L.LightningDataModule):\n",
    "    def __init__(self, tuple_size: int, range_size: int, batch_size: int):\n",
    "        super().__init__()\n",
    "        self.tuple_size = tuple_size\n",
    "        self.range_size = range_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.train_data = None\n",
    "        self.val_data = None\n",
    "        self.test_data = None\n",
    "\n",
    "    def setup(self, stage: str | None = None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            all_combinations = torch.tensor(\n",
    "                list(itertools.product(range(self.range_size), repeat=self.tuple_size))\n",
    "            )\n",
    "            indices = torch.randperm(len(all_combinations))\n",
    "\n",
    "            train_size = int(len(all_combinations) * 0.8)\n",
    "            train_indices = indices[:train_size]\n",
    "            val_indices = indices[train_size:]\n",
    "\n",
    "            train_tensor = all_combinations[train_indices]\n",
    "            val_tensor = all_combinations[val_indices]\n",
    "\n",
    "            self.train_data = TensorDataset(train_tensor)\n",
    "            self.val_data = TensorDataset(val_tensor)\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader[Tuple[torch.Tensor, ...]]:\n",
    "        assert self.train_data is not None\n",
    "        return DataLoader(\n",
    "            self.train_data, batch_size=self.batch_size, shuffle=True, num_workers=4\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self) -> DataLoader[Tuple[torch.Tensor, ...]]:\n",
    "        assert self.val_data is not None\n",
    "        return DataLoader(self.val_data, batch_size=self.batch_size, num_workers=4)\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader[Tuple[torch.Tensor, ...]]:\n",
    "        assert self.test_data is not None\n",
    "        return DataLoader(self.test_data, batch_size=self.batch_size, num_workers=4)\n",
    "\n",
    "\n",
    "class TupleAutoencoder(L.LightningModule):\n",
    "    def __init__(self, tuple_length: int, range_size: int, embedding_dim: int):\n",
    "        super().__init__()\n",
    "        self.tuple_length = tuple_length\n",
    "        self.range_size = range_size\n",
    "\n",
    "        self.embedding = nn.Embedding(range_size, embedding_dim)\n",
    "        self.linear = nn.Linear(tuple_length * embedding_dim, tuple_length * range_size)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        embedded = self.embedding(x)\n",
    "        embedded_flat = embedded.view(batch_size, -1)\n",
    "        output = self.linear(embedded_flat)\n",
    "        output = output.view(batch_size, self.tuple_length, self.range_size)\n",
    "        output = F.softmax(output, dim=-1)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def _compute_loss(self, batch: torch.Tensor) -> torch.Tensor:\n",
    "        x = batch[0]\n",
    "        output = self(x)\n",
    "\n",
    "        loss = F.nll_loss(\n",
    "            output.log().view(-1, self.range_size), x.view(-1), reduction=\"sum\"\n",
    "        )\n",
    "        return loss / x.size(0)\n",
    "\n",
    "    def training_step(self, batch: torch.Tensor, batch_idx: int) -> torch.Tensor:\n",
    "        loss = self._compute_loss(batch)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: torch.Tensor, batch_idx: int):\n",
    "        loss = self._compute_loss(batch)\n",
    "        self.log(\"val_loss\", loss)\n",
    "\n",
    "    def configure_optimizers(self) -> torch.optim.Optimizer:\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "TUPLE_SIZE = 3\n",
    "RANGE_SIZE = 50\n",
    "EMBEDDING_DIM = 2\n",
    "BATCH_SIZE = 2048\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "datamodule = TupleDataModule(\n",
    "    tuple_size=TUPLE_SIZE, range_size=RANGE_SIZE, batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "model = TupleAutoencoder(TUPLE_SIZE, RANGE_SIZE, EMBEDDING_DIM)\n",
    "\n",
    "run_name = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "wandb_logger = WandbLogger(run_name, project=\"tuple-autoencoder\")\n",
    "\n",
    "log_dir = Path(\"logs\") / run_name\n",
    "plot_callback = PlotEmbeddingsCallback(log_dir)\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=NUM_EPOCHS,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[plot_callback],\n",
    ")\n",
    "\n",
    "trainer.fit(model=model, datamodule=datamodule)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
